{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==1.15\n",
        "!pip install keras==2.1.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPVSp7GTSRsS",
        "outputId": "c553280b-7a50-4402-940f-77c06b4b2b6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==1.15\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 8.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.13.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.37.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.43.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=b1dcda3d1a5a147e8b32274ad4f95a452617f11cfec0ff57403206595da3d961\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "Collecting keras==2.1.5\n",
            "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334 kB)\n",
            "\u001b[K     |████████████████████████████████| 334 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.21.5)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.1.5 which is incompatible.\n",
            "tensorflow 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of training a gan on mnist\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTUvaEvNU7bY",
        "outputId": "62f06724-eccf-4f40-c0b6-f525947c2e94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the discriminator model\n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "MN32vAWuVakn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator model\n",
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\t# upsample to 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "C6UDQlnRVgY8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GAN model\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(g_model)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(d_model)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "qYn79yLvVs9g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load mnist training images\n",
        "def load_real_samples():\n",
        "\t(trainX, _), (_, _) = load_data()\n",
        "\t# expand to 3d, e.g. add channels dimension\n",
        "\tX = expand_dims(trainX, axis=-1)\n",
        "\t# convert from unsigned ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [0,1]\n",
        "\tX = X / 255.0\n",
        "\treturn X"
      ],
      "metadata": {
        "id": "fgM-MGilV2ya"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "metadata": {
        "id": "eAM7VyUhWApA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "metadata": {
        "id": "gA6SDVzLWEoe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "metadata": {
        "id": "xa2HVwAxWHc3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create and save a plot of generated images (reversed grayscale)\n",
        "def save_plot(examples, epoch, n=10):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tpyplot.savefig(filename)\n",
        "\tpyplot.close()"
      ],
      "metadata": {
        "id": "x4me2XwIWL7c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "\t# prepare real samples\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save plot\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model tile file\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "\tg_model.save(filename)"
      ],
      "metadata": {
        "id": "xbBm8UteWPqS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches over the training set\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# create training set for the discriminator\n",
        "\t\t\tX, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss, _ = d_model.train_on_batch(X, y)\n",
        "\t\t\t# prepare points in latent space as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\t# create inverted labels for the fake samples\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\t# update the generator via the discriminator's error\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\t# summarize loss on this batch\n",
        "\t\t\tprint('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "\t\t# evaluate the model performance, sometimes\n",
        "\t\tif (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "wRNhBEx0WXuF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9eGBcHc0Wb9b",
        "outputId": "98122dfe-7d85-496f-d385-add020b806eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3069: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2499: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:963: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            ">1, 1/234, d=0.684, g=0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1, 2/234, d=0.679, g=0.747\n",
            ">1, 3/234, d=0.666, g=0.765\n",
            ">1, 4/234, d=0.661, g=0.790\n",
            ">1, 5/234, d=0.651, g=0.809\n",
            ">1, 6/234, d=0.651, g=0.823\n",
            ">1, 7/234, d=0.641, g=0.846\n",
            ">1, 8/234, d=0.637, g=0.848\n",
            ">1, 9/234, d=0.633, g=0.854\n",
            ">1, 10/234, d=0.632, g=0.846\n",
            ">1, 11/234, d=0.635, g=0.833\n",
            ">1, 12/234, d=0.642, g=0.810\n",
            ">1, 13/234, d=0.643, g=0.782\n",
            ">1, 14/234, d=0.646, g=0.759\n",
            ">1, 15/234, d=0.650, g=0.739\n",
            ">1, 16/234, d=0.648, g=0.724\n",
            ">1, 17/234, d=0.647, g=0.714\n",
            ">1, 18/234, d=0.636, g=0.707\n",
            ">1, 19/234, d=0.634, g=0.703\n",
            ">1, 20/234, d=0.626, g=0.700\n",
            ">1, 21/234, d=0.616, g=0.698\n",
            ">1, 22/234, d=0.611, g=0.698\n",
            ">1, 23/234, d=0.603, g=0.697\n",
            ">1, 24/234, d=0.593, g=0.698\n",
            ">1, 25/234, d=0.581, g=0.698\n",
            ">1, 26/234, d=0.566, g=0.698\n",
            ">1, 27/234, d=0.556, g=0.699\n",
            ">1, 28/234, d=0.550, g=0.700\n",
            ">1, 29/234, d=0.535, g=0.701\n",
            ">1, 30/234, d=0.527, g=0.702\n",
            ">1, 31/234, d=0.520, g=0.703\n",
            ">1, 32/234, d=0.509, g=0.704\n",
            ">1, 33/234, d=0.501, g=0.706\n",
            ">1, 34/234, d=0.483, g=0.707\n",
            ">1, 35/234, d=0.478, g=0.708\n",
            ">1, 36/234, d=0.473, g=0.710\n",
            ">1, 37/234, d=0.456, g=0.712\n",
            ">1, 38/234, d=0.450, g=0.714\n",
            ">1, 39/234, d=0.437, g=0.715\n",
            ">1, 40/234, d=0.432, g=0.718\n",
            ">1, 41/234, d=0.424, g=0.720\n",
            ">1, 42/234, d=0.415, g=0.724\n",
            ">1, 43/234, d=0.411, g=0.726\n",
            ">1, 44/234, d=0.401, g=0.730\n",
            ">1, 45/234, d=0.400, g=0.732\n",
            ">1, 46/234, d=0.395, g=0.737\n",
            ">1, 47/234, d=0.386, g=0.741\n",
            ">1, 48/234, d=0.382, g=0.746\n",
            ">1, 49/234, d=0.375, g=0.752\n",
            ">1, 50/234, d=0.368, g=0.758\n",
            ">1, 51/234, d=0.362, g=0.766\n",
            ">1, 52/234, d=0.359, g=0.772\n",
            ">1, 53/234, d=0.349, g=0.781\n",
            ">1, 54/234, d=0.348, g=0.792\n",
            ">1, 55/234, d=0.339, g=0.803\n",
            ">1, 56/234, d=0.333, g=0.813\n",
            ">1, 57/234, d=0.320, g=0.828\n",
            ">1, 58/234, d=0.322, g=0.841\n",
            ">1, 59/234, d=0.315, g=0.856\n",
            ">1, 60/234, d=0.308, g=0.873\n",
            ">1, 61/234, d=0.303, g=0.893\n",
            ">1, 62/234, d=0.292, g=0.912\n",
            ">1, 63/234, d=0.284, g=0.935\n",
            ">1, 64/234, d=0.274, g=0.961\n",
            ">1, 65/234, d=0.266, g=0.986\n",
            ">1, 66/234, d=0.260, g=1.010\n",
            ">1, 67/234, d=0.250, g=1.044\n",
            ">1, 68/234, d=0.238, g=1.071\n",
            ">1, 69/234, d=0.234, g=1.110\n",
            ">1, 70/234, d=0.221, g=1.143\n",
            ">1, 71/234, d=0.216, g=1.183\n",
            ">1, 72/234, d=0.207, g=1.219\n",
            ">1, 73/234, d=0.195, g=1.268\n",
            ">1, 74/234, d=0.186, g=1.309\n",
            ">1, 75/234, d=0.175, g=1.355\n",
            ">1, 76/234, d=0.172, g=1.404\n",
            ">1, 77/234, d=0.162, g=1.455\n",
            ">1, 78/234, d=0.153, g=1.505\n",
            ">1, 79/234, d=0.146, g=1.556\n",
            ">1, 80/234, d=0.142, g=1.609\n",
            ">1, 81/234, d=0.132, g=1.657\n",
            ">1, 82/234, d=0.125, g=1.708\n",
            ">1, 83/234, d=0.116, g=1.759\n",
            ">1, 84/234, d=0.114, g=1.813\n",
            ">1, 85/234, d=0.109, g=1.854\n",
            ">1, 86/234, d=0.120, g=1.824\n",
            ">1, 87/234, d=0.225, g=1.263\n",
            ">1, 88/234, d=1.694, g=0.091\n",
            ">1, 89/234, d=2.726, g=0.021\n",
            ">1, 90/234, d=2.539, g=0.032\n",
            ">1, 91/234, d=2.052, g=0.086\n",
            ">1, 92/234, d=1.508, g=0.211\n",
            ">1, 93/234, d=1.097, g=0.457\n",
            ">1, 94/234, d=0.761, g=0.846\n",
            ">1, 95/234, d=0.572, g=1.260\n",
            ">1, 96/234, d=0.451, g=1.651\n",
            ">1, 97/234, d=0.408, g=1.924\n",
            ">1, 98/234, d=0.389, g=2.087\n",
            ">1, 99/234, d=0.373, g=2.139\n",
            ">1, 100/234, d=0.354, g=2.167\n",
            ">1, 101/234, d=0.326, g=2.208\n",
            ">1, 102/234, d=0.322, g=2.075\n",
            ">1, 103/234, d=0.323, g=2.018\n",
            ">1, 104/234, d=0.289, g=1.900\n",
            ">1, 105/234, d=0.323, g=1.827\n",
            ">1, 106/234, d=0.332, g=1.696\n",
            ">1, 107/234, d=0.335, g=1.539\n",
            ">1, 108/234, d=0.342, g=1.434\n",
            ">1, 109/234, d=0.340, g=1.386\n",
            ">1, 110/234, d=0.370, g=1.355\n",
            ">1, 111/234, d=0.372, g=1.261\n",
            ">1, 112/234, d=0.402, g=1.252\n",
            ">1, 113/234, d=0.416, g=1.215\n",
            ">1, 114/234, d=0.411, g=1.189\n",
            ">1, 115/234, d=0.416, g=1.145\n",
            ">1, 116/234, d=0.416, g=1.133\n",
            ">1, 117/234, d=0.443, g=1.097\n",
            ">1, 118/234, d=0.437, g=1.064\n",
            ">1, 119/234, d=0.458, g=1.048\n",
            ">1, 120/234, d=0.483, g=1.003\n",
            ">1, 121/234, d=0.485, g=0.959\n",
            ">1, 122/234, d=0.512, g=0.951\n",
            ">1, 123/234, d=0.530, g=0.961\n",
            ">1, 124/234, d=0.519, g=0.915\n",
            ">1, 125/234, d=0.537, g=0.933\n",
            ">1, 126/234, d=0.517, g=0.920\n",
            ">1, 127/234, d=0.526, g=0.905\n",
            ">1, 128/234, d=0.528, g=0.919\n",
            ">1, 129/234, d=0.525, g=0.933\n",
            ">1, 130/234, d=0.521, g=0.937\n",
            ">1, 131/234, d=0.523, g=0.955\n",
            ">1, 132/234, d=0.507, g=1.002\n",
            ">1, 133/234, d=0.513, g=1.020\n",
            ">1, 134/234, d=0.505, g=1.026\n",
            ">1, 135/234, d=0.467, g=1.050\n",
            ">1, 136/234, d=0.465, g=1.068\n",
            ">1, 137/234, d=0.447, g=1.077\n",
            ">1, 138/234, d=0.456, g=1.084\n",
            ">1, 139/234, d=0.435, g=1.103\n",
            ">1, 140/234, d=0.452, g=1.104\n",
            ">1, 141/234, d=0.414, g=1.123\n",
            ">1, 142/234, d=0.411, g=1.133\n",
            ">1, 143/234, d=0.401, g=1.147\n",
            ">1, 144/234, d=0.381, g=1.150\n",
            ">1, 145/234, d=0.382, g=1.176\n",
            ">1, 146/234, d=0.374, g=1.193\n",
            ">1, 147/234, d=0.362, g=1.209\n",
            ">1, 148/234, d=0.355, g=1.220\n",
            ">1, 149/234, d=0.340, g=1.234\n",
            ">1, 150/234, d=0.346, g=1.256\n",
            ">1, 151/234, d=0.321, g=1.281\n",
            ">1, 152/234, d=0.324, g=1.290\n",
            ">1, 153/234, d=0.318, g=1.310\n",
            ">1, 154/234, d=0.310, g=1.309\n",
            ">1, 155/234, d=0.294, g=1.317\n",
            ">1, 156/234, d=0.297, g=1.343\n",
            ">1, 157/234, d=0.287, g=1.345\n",
            ">1, 158/234, d=0.295, g=1.364\n",
            ">1, 159/234, d=0.299, g=1.360\n",
            ">1, 160/234, d=0.349, g=1.288\n",
            ">1, 161/234, d=0.462, g=0.913\n",
            ">1, 162/234, d=1.210, g=0.263\n",
            ">1, 163/234, d=1.055, g=0.509\n",
            ">1, 164/234, d=0.897, g=0.639\n",
            ">1, 165/234, d=0.938, g=0.613\n",
            ">1, 166/234, d=0.978, g=0.497\n",
            ">1, 167/234, d=1.105, g=0.371\n",
            ">1, 168/234, d=1.194, g=0.327\n",
            ">1, 169/234, d=1.181, g=0.397\n",
            ">1, 170/234, d=1.126, g=0.421\n",
            ">1, 171/234, d=1.047, g=0.457\n",
            ">1, 172/234, d=1.013, g=0.501\n",
            ">1, 173/234, d=0.966, g=0.545\n",
            ">1, 174/234, d=0.930, g=0.568\n",
            ">1, 175/234, d=0.864, g=0.597\n",
            ">1, 176/234, d=0.850, g=0.625\n",
            ">1, 177/234, d=0.853, g=0.624\n",
            ">1, 178/234, d=0.800, g=0.634\n",
            ">1, 179/234, d=0.798, g=0.666\n",
            ">1, 180/234, d=0.782, g=0.651\n",
            ">1, 181/234, d=0.774, g=0.677\n",
            ">1, 182/234, d=0.727, g=0.678\n",
            ">1, 183/234, d=0.751, g=0.703\n",
            ">1, 184/234, d=0.759, g=0.733\n",
            ">1, 185/234, d=0.753, g=0.734\n",
            ">1, 186/234, d=0.793, g=0.749\n",
            ">1, 187/234, d=0.778, g=0.766\n",
            ">1, 188/234, d=0.807, g=0.753\n",
            ">1, 189/234, d=0.844, g=0.767\n",
            ">1, 190/234, d=0.844, g=0.818\n",
            ">1, 191/234, d=0.848, g=0.900\n",
            ">1, 192/234, d=0.817, g=0.950\n",
            ">1, 193/234, d=0.830, g=0.996\n",
            ">1, 194/234, d=0.822, g=0.976\n",
            ">1, 195/234, d=0.825, g=1.017\n",
            ">1, 196/234, d=0.805, g=0.955\n",
            ">1, 197/234, d=0.813, g=0.940\n",
            ">1, 198/234, d=0.782, g=0.882\n",
            ">1, 199/234, d=0.787, g=0.872\n",
            ">1, 200/234, d=0.773, g=0.836\n",
            ">1, 201/234, d=0.779, g=0.837\n",
            ">1, 202/234, d=0.764, g=0.836\n",
            ">1, 203/234, d=0.754, g=0.806\n",
            ">1, 204/234, d=0.752, g=0.813\n",
            ">1, 205/234, d=0.761, g=0.800\n",
            ">1, 206/234, d=0.742, g=0.790\n",
            ">1, 207/234, d=0.751, g=0.789\n",
            ">1, 208/234, d=0.741, g=0.783\n",
            ">1, 209/234, d=0.729, g=0.782\n",
            ">1, 210/234, d=0.731, g=0.795\n",
            ">1, 211/234, d=0.719, g=0.789\n",
            ">1, 212/234, d=0.718, g=0.799\n",
            ">1, 213/234, d=0.710, g=0.785\n",
            ">1, 214/234, d=0.713, g=0.821\n",
            ">1, 215/234, d=0.691, g=0.804\n",
            ">1, 216/234, d=0.667, g=0.775\n",
            ">1, 217/234, d=0.677, g=0.791\n",
            ">1, 218/234, d=0.651, g=0.789\n",
            ">1, 219/234, d=0.662, g=0.770\n",
            ">1, 220/234, d=0.653, g=0.777\n",
            ">1, 221/234, d=0.656, g=0.777\n",
            ">1, 222/234, d=0.636, g=0.782\n",
            ">1, 223/234, d=0.652, g=0.778\n",
            ">1, 224/234, d=0.649, g=0.784\n",
            ">1, 225/234, d=0.625, g=0.777\n",
            ">1, 226/234, d=0.647, g=0.770\n",
            ">1, 227/234, d=0.655, g=0.768\n",
            ">1, 228/234, d=0.627, g=0.780\n",
            ">1, 229/234, d=0.639, g=0.775\n",
            ">1, 230/234, d=0.668, g=0.770\n",
            ">1, 231/234, d=0.654, g=0.806\n",
            ">1, 232/234, d=0.671, g=0.792\n",
            ">1, 233/234, d=0.663, g=0.817\n",
            ">1, 234/234, d=0.676, g=0.807\n",
            ">2, 1/234, d=0.679, g=0.797\n",
            ">2, 2/234, d=0.693, g=0.788\n",
            ">2, 3/234, d=0.720, g=0.794\n",
            ">2, 4/234, d=0.704, g=0.768\n",
            ">2, 5/234, d=0.703, g=0.756\n",
            ">2, 6/234, d=0.704, g=0.737\n",
            ">2, 7/234, d=0.714, g=0.728\n",
            ">2, 8/234, d=0.724, g=0.720\n",
            ">2, 9/234, d=0.717, g=0.699\n",
            ">2, 10/234, d=0.709, g=0.711\n",
            ">2, 11/234, d=0.721, g=0.691\n",
            ">2, 12/234, d=0.725, g=0.693\n",
            ">2, 13/234, d=0.698, g=0.698\n",
            ">2, 14/234, d=0.717, g=0.677\n",
            ">2, 15/234, d=0.725, g=0.704\n",
            ">2, 16/234, d=0.721, g=0.701\n",
            ">2, 17/234, d=0.702, g=0.717\n",
            ">2, 18/234, d=0.713, g=0.717\n",
            ">2, 19/234, d=0.707, g=0.712\n",
            ">2, 20/234, d=0.713, g=0.715\n",
            ">2, 21/234, d=0.701, g=0.709\n",
            ">2, 22/234, d=0.714, g=0.707\n",
            ">2, 23/234, d=0.694, g=0.697\n",
            ">2, 24/234, d=0.697, g=0.682\n",
            ">2, 25/234, d=0.692, g=0.675\n",
            ">2, 26/234, d=0.692, g=0.695\n",
            ">2, 27/234, d=0.680, g=0.675\n",
            ">2, 28/234, d=0.691, g=0.690\n",
            ">2, 29/234, d=0.685, g=0.695\n",
            ">2, 30/234, d=0.687, g=0.709\n",
            ">2, 31/234, d=0.697, g=0.681\n",
            ">2, 32/234, d=0.691, g=0.691\n",
            ">2, 33/234, d=0.693, g=0.699\n",
            ">2, 34/234, d=0.704, g=0.697\n",
            ">2, 35/234, d=0.680, g=0.688\n",
            ">2, 36/234, d=0.679, g=0.690\n",
            ">2, 37/234, d=0.695, g=0.693\n",
            ">2, 38/234, d=0.699, g=0.690\n",
            ">2, 39/234, d=0.711, g=0.689\n",
            ">2, 40/234, d=0.707, g=0.684\n",
            ">2, 41/234, d=0.707, g=0.660\n",
            ">2, 42/234, d=0.713, g=0.692\n",
            ">2, 43/234, d=0.709, g=0.662\n",
            ">2, 44/234, d=0.735, g=0.681\n",
            ">2, 45/234, d=0.726, g=0.697\n",
            ">2, 46/234, d=0.714, g=0.676\n",
            ">2, 47/234, d=0.749, g=0.662\n",
            ">2, 48/234, d=0.728, g=0.675\n",
            ">2, 49/234, d=0.742, g=0.669\n",
            ">2, 50/234, d=0.742, g=0.675\n",
            ">2, 51/234, d=0.740, g=0.681\n",
            ">2, 52/234, d=0.728, g=0.663\n",
            ">2, 53/234, d=0.731, g=0.678\n",
            ">2, 54/234, d=0.742, g=0.686\n",
            ">2, 55/234, d=0.741, g=0.699\n",
            ">2, 56/234, d=0.735, g=0.697\n",
            ">2, 57/234, d=0.699, g=0.696\n",
            ">2, 58/234, d=0.717, g=0.681\n",
            ">2, 59/234, d=0.710, g=0.690\n",
            ">2, 60/234, d=0.705, g=0.713\n",
            ">2, 61/234, d=0.693, g=0.717\n",
            ">2, 62/234, d=0.696, g=0.737\n",
            ">2, 63/234, d=0.683, g=0.743\n",
            ">2, 64/234, d=0.666, g=0.775\n",
            ">2, 65/234, d=0.662, g=0.766\n",
            ">2, 66/234, d=0.658, g=0.781\n",
            ">2, 67/234, d=0.646, g=0.779\n",
            ">2, 68/234, d=0.648, g=0.770\n",
            ">2, 69/234, d=0.658, g=0.792\n",
            ">2, 70/234, d=0.657, g=0.774\n",
            ">2, 71/234, d=0.651, g=0.771\n",
            ">2, 72/234, d=0.643, g=0.760\n",
            ">2, 73/234, d=0.642, g=0.761\n",
            ">2, 74/234, d=0.643, g=0.755\n",
            ">2, 75/234, d=0.657, g=0.746\n",
            ">2, 76/234, d=0.655, g=0.743\n",
            ">2, 77/234, d=0.645, g=0.732\n",
            ">2, 78/234, d=0.643, g=0.722\n",
            ">2, 79/234, d=0.646, g=0.711\n",
            ">2, 80/234, d=0.654, g=0.733\n",
            ">2, 81/234, d=0.669, g=0.719\n",
            ">2, 82/234, d=0.682, g=0.727\n",
            ">2, 83/234, d=0.657, g=0.724\n",
            ">2, 84/234, d=0.666, g=0.732\n",
            ">2, 85/234, d=0.673, g=0.744\n",
            ">2, 86/234, d=0.668, g=0.746\n",
            ">2, 87/234, d=0.687, g=0.758\n",
            ">2, 88/234, d=0.685, g=0.736\n",
            ">2, 89/234, d=0.697, g=0.721\n",
            ">2, 90/234, d=0.683, g=0.714\n",
            ">2, 91/234, d=0.708, g=0.738\n",
            ">2, 92/234, d=0.695, g=0.708\n",
            ">2, 93/234, d=0.692, g=0.694\n",
            ">2, 94/234, d=0.722, g=0.701\n",
            ">2, 95/234, d=0.718, g=0.697\n",
            ">2, 96/234, d=0.719, g=0.684\n",
            ">2, 97/234, d=0.732, g=0.702\n",
            ">2, 98/234, d=0.766, g=0.684\n",
            ">2, 99/234, d=0.751, g=0.695\n",
            ">2, 100/234, d=0.745, g=0.699\n",
            ">2, 101/234, d=0.759, g=0.699\n",
            ">2, 102/234, d=0.757, g=0.692\n",
            ">2, 103/234, d=0.744, g=0.688\n",
            ">2, 104/234, d=0.746, g=0.704\n",
            ">2, 105/234, d=0.749, g=0.701\n",
            ">2, 106/234, d=0.749, g=0.705\n",
            ">2, 107/234, d=0.744, g=0.682\n",
            ">2, 108/234, d=0.737, g=0.695\n",
            ">2, 109/234, d=0.735, g=0.702\n",
            ">2, 110/234, d=0.726, g=0.693\n",
            ">2, 111/234, d=0.736, g=0.714\n",
            ">2, 112/234, d=0.717, g=0.721\n",
            ">2, 113/234, d=0.697, g=0.709\n",
            ">2, 114/234, d=0.710, g=0.719\n",
            ">2, 115/234, d=0.688, g=0.727\n",
            ">2, 116/234, d=0.681, g=0.732\n",
            ">2, 117/234, d=0.676, g=0.732\n",
            ">2, 118/234, d=0.682, g=0.736\n",
            ">2, 119/234, d=0.668, g=0.727\n",
            ">2, 120/234, d=0.668, g=0.739\n",
            ">2, 121/234, d=0.662, g=0.732\n",
            ">2, 122/234, d=0.670, g=0.732\n",
            ">2, 123/234, d=0.658, g=0.725\n",
            ">2, 124/234, d=0.655, g=0.737\n",
            ">2, 125/234, d=0.657, g=0.730\n",
            ">2, 126/234, d=0.670, g=0.724\n",
            ">2, 127/234, d=0.653, g=0.738\n",
            ">2, 128/234, d=0.653, g=0.747\n",
            ">2, 129/234, d=0.666, g=0.736\n",
            ">2, 130/234, d=0.652, g=0.729\n",
            ">2, 131/234, d=0.645, g=0.741\n",
            ">2, 132/234, d=0.679, g=0.734\n",
            ">2, 133/234, d=0.659, g=0.751\n",
            ">2, 134/234, d=0.673, g=0.774\n",
            ">2, 135/234, d=0.687, g=0.755\n",
            ">2, 136/234, d=0.692, g=0.748\n",
            ">2, 137/234, d=0.689, g=0.742\n",
            ">2, 138/234, d=0.699, g=0.741\n",
            ">2, 139/234, d=0.687, g=0.729\n",
            ">2, 140/234, d=0.698, g=0.716\n",
            ">2, 141/234, d=0.696, g=0.714\n",
            ">2, 142/234, d=0.691, g=0.712\n",
            ">2, 143/234, d=0.705, g=0.717\n",
            ">2, 144/234, d=0.704, g=0.712\n",
            ">2, 145/234, d=0.702, g=0.688\n",
            ">2, 146/234, d=0.699, g=0.701\n",
            ">2, 147/234, d=0.694, g=0.700\n",
            ">2, 148/234, d=0.713, g=0.696\n",
            ">2, 149/234, d=0.709, g=0.705\n",
            ">2, 150/234, d=0.707, g=0.709\n",
            ">2, 151/234, d=0.705, g=0.732\n",
            ">2, 152/234, d=0.715, g=0.714\n",
            ">2, 153/234, d=0.703, g=0.700\n",
            ">2, 154/234, d=0.701, g=0.716\n",
            ">2, 155/234, d=0.705, g=0.711\n",
            ">2, 156/234, d=0.723, g=0.699\n",
            ">2, 157/234, d=0.718, g=0.702\n",
            ">2, 158/234, d=0.716, g=0.686\n",
            ">2, 159/234, d=0.719, g=0.695\n",
            ">2, 160/234, d=0.716, g=0.706\n",
            ">2, 161/234, d=0.715, g=0.697\n",
            ">2, 162/234, d=0.716, g=0.705\n",
            ">2, 163/234, d=0.712, g=0.709\n",
            ">2, 164/234, d=0.716, g=0.691\n",
            ">2, 165/234, d=0.717, g=0.696\n",
            ">2, 166/234, d=0.731, g=0.684\n",
            ">2, 167/234, d=0.716, g=0.689\n",
            ">2, 168/234, d=0.718, g=0.694\n",
            ">2, 169/234, d=0.726, g=0.706\n",
            ">2, 170/234, d=0.734, g=0.715\n",
            ">2, 171/234, d=0.724, g=0.694\n",
            ">2, 172/234, d=0.733, g=0.693\n",
            ">2, 173/234, d=0.721, g=0.697\n",
            ">2, 174/234, d=0.733, g=0.715\n",
            ">2, 175/234, d=0.728, g=0.710\n",
            ">2, 176/234, d=0.728, g=0.695\n",
            ">2, 177/234, d=0.724, g=0.718\n",
            ">2, 178/234, d=0.722, g=0.710\n",
            ">2, 179/234, d=0.713, g=0.712\n",
            ">2, 180/234, d=0.701, g=0.719\n",
            ">2, 181/234, d=0.703, g=0.724\n",
            ">2, 182/234, d=0.706, g=0.714\n",
            ">2, 183/234, d=0.703, g=0.734\n",
            ">2, 184/234, d=0.705, g=0.723\n",
            ">2, 185/234, d=0.700, g=0.741\n",
            ">2, 186/234, d=0.694, g=0.749\n",
            ">2, 187/234, d=0.680, g=0.764\n",
            ">2, 188/234, d=0.679, g=0.757\n",
            ">2, 189/234, d=0.671, g=0.757\n",
            ">2, 190/234, d=0.664, g=0.757\n",
            ">2, 191/234, d=0.667, g=0.753\n",
            ">2, 192/234, d=0.662, g=0.761\n",
            ">2, 193/234, d=0.667, g=0.775\n",
            ">2, 194/234, d=0.667, g=0.764\n",
            ">2, 195/234, d=0.657, g=0.744\n",
            ">2, 196/234, d=0.642, g=0.759\n",
            ">2, 197/234, d=0.650, g=0.739\n",
            ">2, 198/234, d=0.640, g=0.762\n",
            ">2, 199/234, d=0.665, g=0.752\n",
            ">2, 200/234, d=0.653, g=0.764\n",
            ">2, 201/234, d=0.668, g=0.772\n",
            ">2, 202/234, d=0.669, g=0.796\n",
            ">2, 203/234, d=0.658, g=0.798\n",
            ">2, 204/234, d=0.668, g=0.796\n",
            ">2, 205/234, d=0.657, g=0.790\n",
            ">2, 206/234, d=0.661, g=0.770\n",
            ">2, 207/234, d=0.662, g=0.747\n",
            ">2, 208/234, d=0.664, g=0.726\n",
            ">2, 209/234, d=0.677, g=0.728\n",
            ">2, 210/234, d=0.676, g=0.711\n",
            ">2, 211/234, d=0.678, g=0.700\n",
            ">2, 212/234, d=0.677, g=0.698\n",
            ">2, 213/234, d=0.690, g=0.696\n",
            ">2, 214/234, d=0.674, g=0.695\n",
            ">2, 215/234, d=0.686, g=0.702\n",
            ">2, 216/234, d=0.694, g=0.710\n",
            ">2, 217/234, d=0.689, g=0.713\n",
            ">2, 218/234, d=0.693, g=0.709\n",
            ">2, 219/234, d=0.718, g=0.737\n",
            ">2, 220/234, d=0.706, g=0.721\n",
            ">2, 221/234, d=0.717, g=0.717\n",
            ">2, 222/234, d=0.715, g=0.720\n",
            ">2, 223/234, d=0.706, g=0.692\n",
            ">2, 224/234, d=0.711, g=0.678\n",
            ">2, 225/234, d=0.718, g=0.688\n",
            ">2, 226/234, d=0.724, g=0.662\n",
            ">2, 227/234, d=0.717, g=0.662\n",
            ">2, 228/234, d=0.729, g=0.668\n",
            ">2, 229/234, d=0.718, g=0.661\n",
            ">2, 230/234, d=0.715, g=0.673\n",
            ">2, 231/234, d=0.727, g=0.661\n",
            ">2, 232/234, d=0.722, g=0.666\n",
            ">2, 233/234, d=0.728, g=0.678\n",
            ">2, 234/234, d=0.729, g=0.690\n",
            ">3, 1/234, d=0.736, g=0.676\n",
            ">3, 2/234, d=0.731, g=0.676\n",
            ">3, 3/234, d=0.719, g=0.665\n",
            ">3, 4/234, d=0.731, g=0.657\n",
            ">3, 5/234, d=0.732, g=0.658\n",
            ">3, 6/234, d=0.723, g=0.680\n",
            ">3, 7/234, d=0.725, g=0.668\n",
            ">3, 8/234, d=0.731, g=0.673\n",
            ">3, 9/234, d=0.718, g=0.669\n",
            ">3, 10/234, d=0.711, g=0.681\n",
            ">3, 11/234, d=0.697, g=0.691\n",
            ">3, 12/234, d=0.703, g=0.691\n",
            ">3, 13/234, d=0.698, g=0.709\n",
            ">3, 14/234, d=0.693, g=0.703\n",
            ">3, 15/234, d=0.693, g=0.712\n",
            ">3, 16/234, d=0.692, g=0.713\n",
            ">3, 17/234, d=0.678, g=0.720\n",
            ">3, 18/234, d=0.682, g=0.725\n",
            ">3, 19/234, d=0.683, g=0.720\n",
            ">3, 20/234, d=0.681, g=0.720\n",
            ">3, 21/234, d=0.665, g=0.724\n",
            ">3, 22/234, d=0.682, g=0.741\n",
            ">3, 23/234, d=0.679, g=0.740\n",
            ">3, 24/234, d=0.668, g=0.737\n",
            ">3, 25/234, d=0.666, g=0.738\n",
            ">3, 26/234, d=0.680, g=0.735\n",
            ">3, 27/234, d=0.667, g=0.737\n",
            ">3, 28/234, d=0.666, g=0.721\n",
            ">3, 29/234, d=0.659, g=0.723\n",
            ">3, 30/234, d=0.663, g=0.721\n",
            ">3, 31/234, d=0.671, g=0.730\n",
            ">3, 32/234, d=0.669, g=0.720\n",
            ">3, 33/234, d=0.687, g=0.733\n",
            ">3, 34/234, d=0.683, g=0.714\n",
            ">3, 35/234, d=0.671, g=0.722\n",
            ">3, 36/234, d=0.662, g=0.721\n",
            ">3, 37/234, d=0.670, g=0.724\n",
            ">3, 38/234, d=0.666, g=0.722\n",
            ">3, 39/234, d=0.680, g=0.721\n",
            ">3, 40/234, d=0.668, g=0.712\n",
            ">3, 41/234, d=0.676, g=0.711\n",
            ">3, 42/234, d=0.677, g=0.709\n",
            ">3, 43/234, d=0.680, g=0.720\n",
            ">3, 44/234, d=0.694, g=0.707\n",
            ">3, 45/234, d=0.692, g=0.707\n",
            ">3, 46/234, d=0.691, g=0.715\n",
            ">3, 47/234, d=0.694, g=0.705\n",
            ">3, 48/234, d=0.686, g=0.697\n",
            ">3, 49/234, d=0.692, g=0.708\n",
            ">3, 50/234, d=0.691, g=0.697\n",
            ">3, 51/234, d=0.699, g=0.701\n",
            ">3, 52/234, d=0.710, g=0.703\n",
            ">3, 53/234, d=0.706, g=0.705\n",
            ">3, 54/234, d=0.702, g=0.714\n",
            ">3, 55/234, d=0.701, g=0.705\n",
            ">3, 56/234, d=0.702, g=0.708\n",
            ">3, 57/234, d=0.713, g=0.704\n",
            ">3, 58/234, d=0.705, g=0.704\n",
            ">3, 59/234, d=0.713, g=0.704\n",
            ">3, 60/234, d=0.708, g=0.697\n",
            ">3, 61/234, d=0.724, g=0.680\n",
            ">3, 62/234, d=0.709, g=0.683\n",
            ">3, 63/234, d=0.719, g=0.684\n",
            ">3, 64/234, d=0.708, g=0.699\n",
            ">3, 65/234, d=0.714, g=0.697\n",
            ">3, 66/234, d=0.721, g=0.705\n",
            ">3, 67/234, d=0.713, g=0.711\n",
            ">3, 68/234, d=0.717, g=0.723\n",
            ">3, 69/234, d=0.708, g=0.710\n",
            ">3, 70/234, d=0.716, g=0.714\n",
            ">3, 71/234, d=0.708, g=0.715\n",
            ">3, 72/234, d=0.724, g=0.714\n",
            ">3, 73/234, d=0.725, g=0.702\n",
            ">3, 74/234, d=0.713, g=0.693\n",
            ">3, 75/234, d=0.715, g=0.696\n",
            ">3, 76/234, d=0.701, g=0.705\n",
            ">3, 77/234, d=0.710, g=0.711\n",
            ">3, 78/234, d=0.694, g=0.739\n",
            ">3, 79/234, d=0.696, g=0.732\n",
            ">3, 80/234, d=0.697, g=0.726\n",
            ">3, 81/234, d=0.698, g=0.740\n",
            ">3, 82/234, d=0.688, g=0.730\n",
            ">3, 83/234, d=0.685, g=0.723\n",
            ">3, 84/234, d=0.684, g=0.736\n",
            ">3, 85/234, d=0.689, g=0.731\n",
            ">3, 86/234, d=0.688, g=0.749\n",
            ">3, 87/234, d=0.677, g=0.754\n",
            ">3, 88/234, d=0.675, g=0.762\n",
            ">3, 89/234, d=0.683, g=0.753\n",
            ">3, 90/234, d=0.678, g=0.752\n",
            ">3, 91/234, d=0.675, g=0.755\n",
            ">3, 92/234, d=0.674, g=0.752\n",
            ">3, 93/234, d=0.665, g=0.758\n",
            ">3, 94/234, d=0.661, g=0.767\n",
            ">3, 95/234, d=0.670, g=0.757\n",
            ">3, 96/234, d=0.669, g=0.769\n",
            ">3, 97/234, d=0.666, g=0.765\n",
            ">3, 98/234, d=0.671, g=0.760\n",
            ">3, 99/234, d=0.668, g=0.750\n",
            ">3, 100/234, d=0.675, g=0.741\n",
            ">3, 101/234, d=0.675, g=0.739\n",
            ">3, 102/234, d=0.676, g=0.740\n",
            ">3, 103/234, d=0.682, g=0.736\n",
            ">3, 104/234, d=0.678, g=0.715\n",
            ">3, 105/234, d=0.679, g=0.717\n",
            ">3, 106/234, d=0.682, g=0.721\n",
            ">3, 107/234, d=0.680, g=0.717\n",
            ">3, 108/234, d=0.681, g=0.736\n",
            ">3, 109/234, d=0.683, g=0.714\n",
            ">3, 110/234, d=0.675, g=0.726\n",
            ">3, 111/234, d=0.697, g=0.712\n",
            ">3, 112/234, d=0.692, g=0.708\n",
            ">3, 113/234, d=0.693, g=0.713\n",
            ">3, 114/234, d=0.701, g=0.705\n",
            ">3, 115/234, d=0.694, g=0.685\n",
            ">3, 116/234, d=0.692, g=0.714\n",
            ">3, 117/234, d=0.696, g=0.701\n",
            ">3, 118/234, d=0.694, g=0.706\n",
            ">3, 119/234, d=0.697, g=0.703\n",
            ">3, 120/234, d=0.692, g=0.705\n",
            ">3, 121/234, d=0.707, g=0.718\n",
            ">3, 122/234, d=0.705, g=0.684\n",
            ">3, 123/234, d=0.709, g=0.687\n",
            ">3, 124/234, d=0.705, g=0.680\n",
            ">3, 125/234, d=0.704, g=0.678\n",
            ">3, 126/234, d=0.695, g=0.697\n",
            ">3, 127/234, d=0.699, g=0.707\n",
            ">3, 128/234, d=0.707, g=0.707\n",
            ">3, 129/234, d=0.712, g=0.699\n",
            ">3, 130/234, d=0.709, g=0.708\n",
            ">3, 131/234, d=0.700, g=0.692\n",
            ">3, 132/234, d=0.719, g=0.698\n",
            ">3, 133/234, d=0.718, g=0.683\n",
            ">3, 134/234, d=0.719, g=0.683\n",
            ">3, 135/234, d=0.717, g=0.679\n",
            ">3, 136/234, d=0.712, g=0.686\n",
            ">3, 137/234, d=0.719, g=0.684\n",
            ">3, 138/234, d=0.712, g=0.688\n",
            ">3, 139/234, d=0.724, g=0.695\n",
            ">3, 140/234, d=0.704, g=0.697\n",
            ">3, 141/234, d=0.725, g=0.692\n",
            ">3, 142/234, d=0.709, g=0.696\n",
            ">3, 143/234, d=0.717, g=0.709\n",
            ">3, 144/234, d=0.719, g=0.700\n",
            ">3, 145/234, d=0.719, g=0.695\n",
            ">3, 146/234, d=0.720, g=0.701\n",
            ">3, 147/234, d=0.701, g=0.687\n",
            ">3, 148/234, d=0.717, g=0.708\n",
            ">3, 149/234, d=0.713, g=0.704\n",
            ">3, 150/234, d=0.704, g=0.711\n",
            ">3, 151/234, d=0.692, g=0.719\n",
            ">3, 152/234, d=0.690, g=0.721\n",
            ">3, 153/234, d=0.700, g=0.737\n",
            ">3, 154/234, d=0.697, g=0.723\n",
            ">3, 155/234, d=0.688, g=0.730\n",
            ">3, 156/234, d=0.687, g=0.731\n",
            ">3, 157/234, d=0.676, g=0.724\n",
            ">3, 158/234, d=0.685, g=0.740\n",
            ">3, 159/234, d=0.687, g=0.738\n",
            ">3, 160/234, d=0.668, g=0.720\n",
            ">3, 161/234, d=0.671, g=0.718\n",
            ">3, 162/234, d=0.675, g=0.727\n",
            ">3, 163/234, d=0.672, g=0.726\n",
            ">3, 164/234, d=0.679, g=0.718\n",
            ">3, 165/234, d=0.669, g=0.718\n",
            ">3, 166/234, d=0.659, g=0.723\n",
            ">3, 167/234, d=0.674, g=0.730\n",
            ">3, 168/234, d=0.668, g=0.727\n",
            ">3, 169/234, d=0.682, g=0.740\n",
            ">3, 170/234, d=0.671, g=0.751\n",
            ">3, 171/234, d=0.670, g=0.732\n",
            ">3, 172/234, d=0.676, g=0.727\n",
            ">3, 173/234, d=0.671, g=0.723\n",
            ">3, 174/234, d=0.689, g=0.726\n",
            ">3, 175/234, d=0.671, g=0.703\n",
            ">3, 176/234, d=0.687, g=0.719\n",
            ">3, 177/234, d=0.677, g=0.707\n",
            ">3, 178/234, d=0.676, g=0.712\n",
            ">3, 179/234, d=0.682, g=0.713\n",
            ">3, 180/234, d=0.688, g=0.714\n",
            ">3, 181/234, d=0.690, g=0.723\n",
            ">3, 182/234, d=0.690, g=0.723\n",
            ">3, 183/234, d=0.691, g=0.712\n",
            ">3, 184/234, d=0.686, g=0.723\n",
            ">3, 185/234, d=0.696, g=0.711\n",
            ">3, 186/234, d=0.693, g=0.705\n",
            ">3, 187/234, d=0.690, g=0.717\n",
            ">3, 188/234, d=0.694, g=0.718\n",
            ">3, 189/234, d=0.686, g=0.724\n",
            ">3, 190/234, d=0.696, g=0.725\n",
            ">3, 191/234, d=0.711, g=0.706\n",
            ">3, 192/234, d=0.690, g=0.713\n",
            ">3, 193/234, d=0.699, g=0.716\n",
            ">3, 194/234, d=0.696, g=0.706\n",
            ">3, 195/234, d=0.702, g=0.705\n",
            ">3, 196/234, d=0.711, g=0.713\n",
            ">3, 197/234, d=0.705, g=0.709\n",
            ">3, 198/234, d=0.707, g=0.716\n",
            ">3, 199/234, d=0.707, g=0.709\n",
            ">3, 200/234, d=0.700, g=0.718\n",
            ">3, 201/234, d=0.709, g=0.701\n",
            ">3, 202/234, d=0.703, g=0.701\n",
            ">3, 203/234, d=0.706, g=0.697\n",
            ">3, 204/234, d=0.720, g=0.694\n",
            ">3, 205/234, d=0.711, g=0.687\n",
            ">3, 206/234, d=0.710, g=0.697\n",
            ">3, 207/234, d=0.710, g=0.684\n",
            ">3, 208/234, d=0.698, g=0.696\n",
            ">3, 209/234, d=0.709, g=0.700\n",
            ">3, 210/234, d=0.709, g=0.712\n",
            ">3, 211/234, d=0.731, g=0.715\n",
            ">3, 212/234, d=0.719, g=0.708\n",
            ">3, 213/234, d=0.717, g=0.716\n",
            ">3, 214/234, d=0.702, g=0.709\n",
            ">3, 215/234, d=0.714, g=0.727\n",
            ">3, 216/234, d=0.704, g=0.722\n",
            ">3, 217/234, d=0.704, g=0.712\n",
            ">3, 218/234, d=0.705, g=0.712\n",
            ">3, 219/234, d=0.704, g=0.719\n",
            ">3, 220/234, d=0.709, g=0.734\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1522f11f604f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-baa9c944eeec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0my_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0;31m# update the generator via the discriminator's error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                         \u001b[0;31m# summarize loss on this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>%d, %d/%d, d=%.3f, g=%.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbat_per_epo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m   1066\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     def test_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}